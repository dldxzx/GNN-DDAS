{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zengxin/anaconda3/envs/fpk/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/zengxin/fpk/pycharm_project/GNN-DDAS\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score, cohen_kappa_score, accuracy_score, auc, roc_auc_score, average_precision_score, precision_score\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "import numpy as np\n",
    "from torch import tensor\n",
    "from utils.dataset import SMILESDataset\n",
    "from utils.resample import resampled\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMILES原子格式\n",
    "smiles_dict = {\"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2, \n",
    "        \"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6, \n",
    "        \"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43, \n",
    "        \"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13, \n",
    "        \"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51, \n",
    "        \"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56, \n",
    "        \"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60, \n",
    "        \"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64,\"*\":65}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecfp6_fingerprint(smiles):\n",
    "    smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 6, nBits=1024)\n",
    "    fingerprint = fingerprint.ToBitString()\n",
    "    return fingerprint\n",
    "\n",
    "def smiles_onehot(smiles=None):\n",
    "    smiles_one_hot = np.zeros((len(smiles),65))\n",
    "    for i, amino_acid in enumerate(smiles):\n",
    "        smiles_one_hot[i, smiles_dict[amino_acid]] = 1\n",
    "    return np.array(smiles_one_hot)\n",
    "def smiles_string(data, max_len):\n",
    "    toks_list = []\n",
    "    mask_attn_list = []\n",
    "    toks = [smiles_dict[char] for char in data]\n",
    "    if len(toks) > max_len:\n",
    "        toks = toks[:max_len]\n",
    "        mask_attn = [1]*max_len\n",
    "    else:\n",
    "        toks = toks + [0] * (max_len - len(toks))\n",
    "        mask_attn = [1] * len(data) + [0] * (max_len - len(data))\n",
    "    return toks,mask_attn\n",
    "# 生成ECFP6分子指纹、ont-hot编码\n",
    "def data_processed(data):\n",
    "    fingerprint_list = []\n",
    "    one_hot_list = []\n",
    "    lable_list = []\n",
    "    toks_list = []\n",
    "    for idx, data in enumerate(data):\n",
    "        fingerprint = generate_ecfp6_fingerprint(data.smiles)\n",
    "        # 将二进制字符串转换为整数\n",
    "        integer_value = int(fingerprint, 2)\n",
    "        # 将整数转换为 NumPy 数组\n",
    "        fingerprint = np.array([int(bit) for bit in bin(integer_value)[2:].zfill(len(fingerprint))])\n",
    "        fingerprint_list.append(fingerprint)\n",
    "        # onehot = smiles_onehot(data.smiles)\n",
    "        # toks,_ = smiles_string(data.smiles,125)\n",
    "        # toks_list.append(toks)\n",
    "        # one_hot_list.append(onehot)\n",
    "        lable_list.append(int(data.y))\n",
    "        # print(idx,fingerprint,data.y.numpy())\n",
    "    return fingerprint_list,lable_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682 166\n"
     ]
    }
   ],
   "source": [
    "train_root = '/home/zengxin/fpk/pycharm_project/GNN-DDAS/data/merge/merge_data/train_data'\n",
    "test_root = '/home/zengxin/fpk/pycharm_project/GNN-DDAS/data/merge/merge_data/test_data'\n",
    "temp_train_root = '/home/zengxin/fpk/pycharm_project/GNN-DDAS/data/merge/merge_data/resample/train'\n",
    "raw_train_root = '/home/zengxin/fpk/pycharm_project/GNN-DDAS/data/merge/merge_data/train_data/raw/train_data.csv'\n",
    "temp_test_root = '/home/zengxin/fpk/pycharm_project/GNN-DDAS/data/merge/merge_data/resample/test'\n",
    "raw_test_root = '/home/zengxin/fpk/pycharm_project/GNN-DDAS/data/merge/merge_data/test_data/raw/test_data.csv'\n",
    "\n",
    "# train_set = SMILESDataset(root=train_root,raw_dataset='train_data.csv',processed_data='train.pt',max_node_num=125)\n",
    "# test_set = SMILESDataset(root=test_root,raw_dataset='test_data.csv',processed_data='test.pt',max_node_num=125)\n",
    "train_set = resampled(temp_train_root=temp_train_root,raw_train_root=raw_train_root,ratio=1)\n",
    "test_set = resampled(temp_train_root=temp_test_root,raw_train_root=raw_test_root,ratio=1)\n",
    "# train_set, test_set = train_test_split(train_set,test_size=0.1,random_state=42)\n",
    "print(len(train_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(rf=None,X_train=None,y_train=None,X_test=None,y_test=None,param=None,cv=5,model_path=None,data_name=None):\n",
    "\n",
    "    gs = GridSearchCV(rf,param_grid=param,cv=cv)\n",
    "    gs.fit(X_train,y_train)\n",
    "    res = gs.score(X_test,y_test)\n",
    "    y_pred = gs.predict(X_test)\n",
    "    y_prob = gs.predict_proba(X_test)[:, 1]\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    ck = cohen_kappa_score(y_test,y_pred)\n",
    "    mcc = matthews_corrcoef(y_test,y_pred)\n",
    "    auprc = average_precision_score(y_test,y_pred)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    best_params = gs.best_params_\n",
    "    # 输出最佳的n_estimators和max_depth\n",
    "    best_n_estimators = best_params[\"n_estimators\"]\n",
    "    best_max_depth = best_params[\"max_depth\"]\n",
    "    print(f'f1:{f1},mcc:{mcc},ck:{ck},acc:{acc},auprc:{auprc}')\n",
    "    print(\"最佳 n_estimators:\", best_n_estimators)\n",
    "    print(\"最佳 max_depth:\", best_max_depth)\n",
    "    filename = model_path + 'RF_' + data_name + '1.pkl'\n",
    "    pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fingerprint,train_label = data_processed(train_set)\n",
    "test_fingerprint,test_lables = data_processed(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================Feature:ECFP\n",
    "rf_ecfp = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc:0.7156336188125999,f1:0.6813186813186813,mcc:0.30696227861823216,ck:0.3012048192771084,acc:0.6506024096385542,auprc:0.5943166605817208\n",
      "最佳 n_estimators: 100\n",
      "最佳 max_depth: 20\n"
     ]
    }
   ],
   "source": [
    "param = {\"n_estimators\": [10,20,30,40,50, 100, 200, 300,],\"max_depth\":[1,2,3,4,5,10,15,20,25,30]}\n",
    "model_path = '/home/zengxin/fpk/pycharm_project/GNN-DDAS/save_model/ML/merge/'\n",
    "rf(rf_ecfp,param=param,X_train=train_fingerprint,y_train=train_label,X_test=test_fingerprint,y_test=test_lables,cv=5,model_path=model_path,data_name='merge_ecfp')\n",
    "# 未进行降采样\n",
    "# Roc:0.6759717739510455,f1:0.0,mcc:0.0,ck:0.0,auprc:0.12134502923976608\n",
    "# 最佳 n_estimators: 10\n",
    "# 最佳 max_depth: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
